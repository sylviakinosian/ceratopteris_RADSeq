---
title: "*Ceratopteris* GBS Pipeline"
author: "Sylvia Kinosian"
output: html_document
---

This pipeline was developed by Zach Gompert, and edited by Sylvia Kinosian. All data analysis except the data visualization were run on the University of Utah [Center for High Performance Computing](https://www.chpc.utah.edu/). This or a similar computing cluster is required for this pipeline. Data visualization was performed in R (v. 3.5.2) on Ubuntu 19.04.

# {.tabset}

## Demultiplexing

This first part uses [Perl 5](http://www.perl.org) scripts to parse the barcodes from the raw FASTQ files, and then split that raw file into FASTQ files for each individual.

Please keep in mind that steps 1 & 2 can take several days to run; plan accordinly.

### Step 1: Parse barcodes
The first script, **parse\_barcodes768.pl**, requires two files: a barcodes file and the raw FASTQ file. The **barcodes.txt** file has three columns: the index name, barcode, and sample name for each indiviual. See barcodes.txt for an example. 

Since we have paired-end reads, we have to run this step twice: once for the forward, and once for the reverse. After splitting out the individuals, we will combine the forward and reverse reads.

```{bash eval=FALSE}
perl parse_barcodes768.pl barcodes_forward.txt rawR1.fastq

perl parse_barcodes768.pl barcodes_reverse.txt rawR2.fastq
```

### Step 2: Split FASTQ by individual 
The next script, **splitFastq\_ms.pl**, requires two files: a list of individuals and the parsed.FASTQ file (one of the output file from **parse\_barcodes768.pl**). The **individuals.txt** file is simply a list of the names for each individual you would like to create a FASTQ file for. This individuals file is a text file contain one column, with one name per row, no header.

```{bash eval=FALSE}
perl splitFastq_ms.pl individuals_forward.txt parsed_rawR1.fastq

perl splitFastq_ms.pl individuals_reverse.txt parsed_rawR2.fastq
```
Now, you should have a two FASTQ files for each individual: one for forward and one for reverse reads. 

### Step 3: Combine paired-end reads

To combine our paired-end reads, we used the program PEAR: Paired-End reAd mergeR (v. 0.9.11). Please see the script **pear.sh** for our exact usage.

```{bash eval=FALSE}
./pear -f forward_read.fastq -r reverse_read.fastq -o outfile_name
```

## Reference genome prep

### Step 1: Index the reference genome. 

Here, we used the Burrows-Wheeler Aligner (BWA v. 0.7.10) to index our reference genome. This give the squence position points for the alignment later on.

```{bash eval=FALSE}
bwa index fern.racon.fasta 
```

### Step 2: Create a sequence dictionary

We used Java (OpenJDK) v. 1.8.0 and PicardTools v. 2.9.0

```{bash eval=FALSE}
java -jar picard.jar CreateSequenceDictionary REFERENCE=fern.racon.fasta OUTPUT=fern.racon.dict
```
### Step 3: Create the fasta index file

We used SAMTOOLS v. 1.5

```{bash eval=FALSE}
samtools faidx fern.racon.fasta
```

Now you should have the following files:

consensus.dict<br>
consensus.fasta<br>
consensus.amb<br>
consensus.ann<br>
consensus.bwt<br>
consensus.fai<br>
consensus.pac<br>
consensus.sa<br>


## Align reads to reference genome

We used the ALN and SAMSE functions of BWA (0.7.10) to align the individuals to the reference genome. The output is a .SAM file for each individual

See script `bwa_aln.sh`

MEM?

```{bash eval=FALSE}
bwa mem -t 10 -w 50 -k 20 -a -C -R "@RG\tID:$ids\tLB:$ids\tSM:$ids\tPL:ILLUMINA" consensus.fasta ind.fastq > out.sam
```

**-t** number of threads<br>
**-k** Maximum seed length<br>
**-w** Band width; gaps longer than INT will not be found. Note that the maximum gap length is also affected by the scoring matrix and the hit length, not solely determined by this option.<br>
**-a** Output all found alignments for single-end or unpaired paired-end reads. These alignments will be flagged as secondary alignments.<br>
**-C** Append append FASTA/Q comment to SAM output<br>
**-R** Complete read group header line.<br>

All other flag values are default.

```{bash eval=FALSE}
bwa aln -n 4 -l 20 -k 2 -t 8 -q 10 $ids.sai $REF $i

bwa samse -n 1 -r "@RG\tID:$ids\tLB:$ids\tSM:$ids\tPL:ILLUMINA" $ids.sam .fastq $ids.sai $i
```

BWA [documentation](http://bio-bwa.sourceforge.net/bwa.shtml).

Flags for ALN:

-n: Maximum edit distance if the value is INT, or the fraction of missing alignments given 2% uniform base error rate if FLOAT.<br>
-l: Take the first INT subsequence as seed. If INT is larger than the query sequence, seeding will be disabled. For long reads, this option is typically ranged from 25 to 35 for ‘-k 2’.<br>
-k: Maximum edit distance in the seed. <br>
-t: Number of threads. <br>
-q: Parameter for read trimming. BWA trims a read down to argmax\_x{\\sum_{i=x+1}^l(INT-q_i)} if q\_l\<INT where l is the original read length.<br>

Flags for SAMSE:

-n: Maximum number of alignments to output in the XA tag for reads paired properly. If a read has more than INT hits, the XA tag will not be written.
-r: Specify the read group; unqiue for a sequencing platform.

#### b. Convert files from .SAM to .BAM, sort, and index the individuals using SAMTOOLS

```{bash eval=FALSE}
samtools view -o *.bam *.sam

samtools sort -o *.sorted.bam *.bam
 
samtools index -b *.sorted.bam
```

### Step 3: Call Variants

#### Step 3a. Process all individuals as diploid
```{bash eval=FALSE}
java -Xmx48g -jar GenomeAnaysisTK.jar -T HaplotypeCaller -R ei_cons.fasta -I bams.list --genotyping_mode DISCOVERY -ploidy 2 -o ice_rawVar.vcf -out_mode EMIT_VARIANTS_ONLY
```

```{bash eval=FALSE}
java -Xmx48g -jar GenomeAnaysisTK.jar -T HaplotypeCaller -R gl_cons.fasta -I bams.list --genotyping_mode DISCOVERY -ploidy 2 -o glc_rawVar.vcf -out_mode EMIT_VARIANTS_ONLY
```

## ENTROPY analysis and visualization

### **Entropy**

Before getting started with Entopry, we need to convert our VCF file to a GL (Genotype Likelihood) file.

We used the perl script vcf2gl.pl to convert our filtered vcf to the simpler .gl format for downstream analysis.

For diploids:

```{bash eval=FALSE}
perl vcf2gl.pl aeAll.vcf
```
This outputs a file called out.recode.gl

Next we are going to convert the GL file to a matrix that we can use in R with DAPC.

```{bash eval=FALSE}
perl gl2genest.pl out.recode.gl
```
This outputs a file called pntest\_out.recode.gl

### Discriminant Analysis of Principle Components 

Among the diploid species, *Pteridium aquilinum* and *P. esculentum*, and the tetraploid species, *P. semihaustatum* and *P. caudatum*, there are 15 sub-species. These distinctions are based mostly on morphology, and so testing the population structure among them will help distinguish the validity of these biological species and sub-species.

##### a. seed entropy with values from DAPC

Using the R package ADEGENET (v. 2.1.1), run a Discriminate Analysis of Principle Componets (DAPC function) to seed values in ENTROPY so we don't get label swapping. We followed the [DAPC vignette](adegenet.r-forge.r-project.org/files/tutorial-dapc.pdf).

```{r eval=FALSE}
library(adegenet)

# read in genotype matrix
d <- read.table("pntest_out.recode.vcf", header = F)

# transform data
dt <- t(d)

# convert to genind object
dg <- df2genind(dt, sep = " ", ploidy = 2)

grp <- find.clusters(dg, max.n.clust = 15)
# number of PCs retained: 60
# number of clusters: 2

head(grp$grp, 97)

# get likelihood assignments

dapc1 <- dapc(dg, grp$grp)
# PCs 60
# discriminant dunctions: 1

write.table(dapc1$posterior, "k_est.txt")
```

#####b. run ENTROPY

```{bash eval=FALSE}
./entropy -b 2000 -t 4 -k 2 -i ae_in.gl -o out.hdf5 -m 1 -w 0 -q pop_ests.txt -s 20
```

#####c. ESTPOST - pulling out meaningful things from entropy

```{bash eval=FALSE}
/home/skinosian/hts_tools/estpost_h5_entropy -o out_d -p deviance -s 3 -w 1 entropy_ae_k2_2.hdf5
```

###**Visualizing Admixture**

```{r eval=FALSE}
# read in files from estpost
k2_1 <- read.csv("k2_1.txt", sep = ',', header = F)
k2_2 <- read.csv("k2_2.txt", sep = ',', header = F)
k2_3 <- read.csv("k2_3.txt", sep = ',', header = F)

names <- read.csv("names.txt", sep ',', header = F)

# this function averages chains for a given k
avg_k <- function(kval, n_inds = 97, chain1, chain2, chain3){
	df <- as.data.frame(matrix(nrow = kval*n_inds,  ncol = 4))
	colnames(df)[1:4] <- c("chain1", "chain2", "chain3", "avg")
	df[,1] <- chain1[,1]	
	df[,2] <- chain2[,1]
	df[,3] <- chain3[,1]
	df[,4] <- rowMeans(df[sapply(df, is.numeric)])
	return(df)
}

avg2 <- avg_k(kval = 2, chain1 = k2_1, chain2 = k2_2, chain3 = k2_3)

# makes a data frame with your averaged chains
make_df <- function(k_file, k_val, n_inds = 97,  names){
	x <- 1
	df <- as.data.frame(matrix(nrow = n_inds, ncol = k_val+x))
	for (i in 1:k_val){
		df[,i] <- k_file[x:(n_inds*i),4]
		x <- x+n_inds
	}
	df[,ncol(df)] <- names
	df <- df[order(df[,ncol(df)]),]
	return(df)
}

df2 <- make_df(kfile = avg2, k_val = 2, names = names)
k2list <- list(k2_ordered[,1:2])

# function to plot each chain for a given k
plot_q_per_chain <- function(kqlist, xlabel, ...){
	cols <- c('#A8FFFD', '#FFA8AA', '#BB61C3', '#69C261','#A39D9D', '#FFFF00', '#C1C6FF','#26CDCD', '#E4D5EF', '#CDBA8F', '#B862D3', '#79D958', '#CA4B87', '#D2C948', '#6386CA', '#D1543B', '#0D0D41')	
	par(mfrow= c(length(kqlist),1), mar=c(4,2,1,1) + 0.1, oma= c(5,0,0,0), mgp= c(0,1,0))
	chain <- seq(1, length(kqlist), 1) 
	for(i in 1:length(kqlist)){
		barplot(t(kqlist[[i]]), beside= F, col= cols, las= 2, axisnames= T, cex.name= 1, cex.axis= 1.2, border= 1, space= c(0.05,0.05), yaxt= 'n', ylab= paste("k =", chain[i+1], sep= ' '), cex.lab= 2, names.arg= xlabel)
		axis(2, at= c(0, 0.5, 1), cex.axis= 1, las= 2, pos= -0.2)
 	}
}

plot_q_per_chain(k2list, df2[,3], 2)
```

## Program Versions

Below is a list of all program versions used in this analysis. **Please note** that newer versions of these software packages *may* work for this pipeline, but be aware that usage often changes with new verions. 

[Perl 5](https://www.perl.org/)

[Pear 0.9.11](https://cme.h-its.org/exelixis/web/software/pear/index.html)

[Python 2.7.13](https://www.python.org/downloads/release/python-2713/)

[SAMtools v. 1.5](https://sourceforge.net/projects/samtools/files/samtools/1.5/)

[SEQTK 1.2-r102-dirty](https://github.com/lh3/seqtk)

[VSEARCH 2.4.2](https://github.com/torognes/vsearch)

[BWA 0.7.15](https://sourceforge.net/projects/bio-bwa/files/)

[PicardTools 2.9.0](https://github.com/broadinstitute/picard/releases)

[GATK v.3.8.0](https://software.broadinstitute.org/gatk/download/archive) - [HaplotypeCaller](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_haplotypecaller_HaplotypeCaller.php)

[ENTROPY & ESTPOST](https://github.com/sylviakinosian/Pteridium_GBS_Pipeline/tree/master/entropy)

[R v. 3.5.2](https://www.r-project.org/)

