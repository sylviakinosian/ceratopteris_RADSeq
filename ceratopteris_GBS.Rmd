---
title: "*Ceratopteris* GBS Pipeline"
author: "Sylvia Kinosian"
output: html_document
---

#{.tabset}

##Demultiplexing

This first part uses Perl scripts to parse the barcodes from the raw GBS .FASTQ data and then split that raw file into indiviual .FASTQ files. Note that all Perl were run using Perl 5 (http://www.perl.org).

###Step 1: Parse barcodes
The first scipt, parse\_barcodes768.pl, requires two files: a barcodes file and the raw FASTQ file. The barcodes.txt file has three columns: the index name, barcode, and sample name for each indiviual. See barcodes.txt for an example. 

Since we have paired-end reads, we have to run this step twice: once for the forward, and once for the reverse. After splitting out the individuals, we will combine the forward and reverse reads.

```{bash eval=FALSE}
parse_barcodes768.pl barcodes_forward.txt rawR1.fastq

parse_barcodes768.pl barcodes_reverse.txt rawR2.fastq
```

###Step 2: Split FASTQ by individual 
The next script, splitFastq\_ms.pl, requires two files: a list of individuals and the parsed.FASTQ file (one of the output file from parse\_barcodes768.pl). The individuals.txt file is simply a list of the names for each individual you would like to create a FASTQ file for. This individuals file is a text file contain one column, with one name per row, no header.

```{bash eval=FALSE}
splitFastq_ms.pl individuals_forward.txt parsed_rawR1.fastq

splitFastq_ms.pl individuals_reverse.txt parsed_rawR2.fastq
```
Now, you should have a two.FASTQ files for each individual: one for forward and one for reverse reads. 

###Step 3: Combine paired-end reads

## Reference genome prep

###Step 1: Index the reference genome. 

Here, we used the Burrow-Wheeler Aligner (BWA v. 0.7.10) to index our reference genome. This give the squence position points for the alignment later on.

```{bash eval=FALSE}
bwa index fern.racon.fasta 
```

###Step 2: Create a sequence dictionary

We used Java (OpenJDK) v. 1.8.0 and PicardTools v. 2.9.0

```{bash eval=FALSE}
java -jar picard.jar CreateSequenceDictionary REFERENCE=fern.racon.fasta OUTPUT=fern.racon.dict
```
###Step 3: Create the fasta index file

We used SAMTOOLS v. 1.5

```{bash eval=FALSE}
samtools faidx fern.racon.fasta
```

##Align reads to reference genome

##ENTROPY analysis and visualization

###**Entropy**

Before getting started with Entopry, we need to convert our VCF file to a GL (Genotype Likelihood) file.

We used the perl script vcf2gl.pl to convert our filtered vcf to the simpler .gl format for downstream analysis.

For diploids:

```{bash eval=FALSE}
perl vcf2gl.pl aeAll.vcf
```
This outputs a file called out.recode.gl

Next we are going to convert the GL file to a matrix that we can use in R with DAPC.

```{bash eval=FALSE}
perl gl2genest.pl out.recode.gl
```
This outputs a file called pntest\_out.recode.gl

###Discriminant Analysis of Principle Components 

Among the diploid species, *Pteridium aquilinum* and *P. esculentum*, and the tetraploid species, *P. semihaustatum* and *P. caudatum*, there are 15 sub-species. These distinctions are based mostly on morphology, and so testing the population structure among them will help distinguish the validity of these biological species and sub-species.

#####a. seed entropy with values from DAPC

Using the R package ADEGENET (v. 2.1.1), run a Discriminate Analysis of Principle Componets (DAPC function) to seed values in ENTROPY so we don't get label swapping. We followed the [DAPC vignette](adegenet.r-forge.r-project.org/files/tutorial-dapc.pdf).

```{r eval=FALSE}
library(adegenet)

# read in genotype matrix
d <- read.table("pntest_out.recode.vcf", header = F)

# transform data
dt <- t(d)

# convert to genind object
dg <- df2genind(dt, sep = " ", ploidy = 2)

grp <- find.clusters(dg, max.n.clust = 15)
# number of PCs retained: 60
# number of clusters: 2

head(grp$grp, 97)

# get likelihood assignments

dapc1 <- dapc(dg, grp$grp)
# PCs 60
# discriminant dunctions: 1

write.table(dapc1$posterior, "k_est.txt")
```

#####b. run ENTROPY

```{bash eval=FALSE}
./entropy -b 2000 -t 4 -k 2 -i ae_in.gl -o out.hdf5 -m 1 -w 0 -q pop_ests.txt -s 20
```

#####c. ESTPOST - pulling out meaningful things from entropy

```{bash eval=FALSE}
/home/skinosian/hts_tools/estpost_h5_entropy -o out_d -p deviance -s 3 -w 1 entropy_ae_k2_2.hdf5
```

###**Visualizing Admixture**

```{r eval=FALSE}
# read in files from estpost
k2_1 <- read.csv("k2_1.txt", sep = ',', header = F)
k2_2 <- read.csv("k2_2.txt", sep = ',', header = F)
k2_3 <- read.csv("k2_3.txt", sep = ',', header = F)

names <- read.csv("names.txt", sep ',', header = F)

# this function averages chains for a given k
avg_k <- function(kval, n_inds = 97, chain1, chain2, chain3){
	df <- as.data.frame(matrix(nrow = kval*n_inds,  ncol = 4))
	colnames(df)[1:4] <- c("chain1", "chain2", "chain3", "avg")
	df[,1] <- chain1[,1]	
	df[,2] <- chain2[,1]
	df[,3] <- chain3[,1]
	df[,4] <- rowMeans(df[sapply(df, is.numeric)])
	return(df)
}

avg2 <- avg_k(kval = 2, chain1 = k2_1, chain2 = k2_2, chain3 = k2_3)

# makes a data frame with your averaged chains
make_df <- function(k_file, k_val, n_inds = 97,  names){
	x <- 1
	df <- as.data.frame(matrix(nrow = n_inds, ncol = k_val+x))
	for (i in 1:k_val){
		df[,i] <- k_file[x:(n_inds*i),4]
		x <- x+n_inds
	}
	df[,ncol(df)] <- names
	df <- df[order(df[,ncol(df)]),]
	return(df)
}

df2 <- make_df(kfile = avg2, k_val = 2, names = names)
k2list <- list(k2_ordered[,1:2])

# function to plot each chain for a given k
plot_q_per_chain <- function(kqlist, xlabel, ...){
	cols <- c('#A8FFFD', '#FFA8AA', '#BB61C3', '#69C261','#A39D9D', '#FFFF00', '#C1C6FF','#26CDCD', '#E4D5EF', '#CDBA8F', '#B862D3', '#79D958', '#CA4B87', '#D2C948', '#6386CA', '#D1543B', '#0D0D41')	
	par(mfrow= c(length(kqlist),1), mar=c(4,2,1,1) + 0.1, oma= c(5,0,0,0), mgp= c(0,1,0))
	chain <- seq(1, length(kqlist), 1) 
	for(i in 1:length(kqlist)){
		barplot(t(kqlist[[i]]), beside= F, col= cols, las= 2, axisnames= T, cex.name= 1, cex.axis= 1.2, border= 1, space= c(0.05,0.05), yaxt= 'n', ylab= paste("k =", chain[i+1], sep= ' '), cex.lab= 2, names.arg= xlabel)
		axis(2, at= c(0, 0.5, 1), cex.axis= 1, las= 2, pos= -0.2)
 	}
}

plot_q_per_chain(k2list, df2[,3], 2)
```

##Program Versions

Below is a list of all program versions used in this analysis. Please note that newer versions of these software packages *may* work for this pipeline, but be aware that usage often changes with new verions. 

[Perl 5](https://www.perl.org/)

[Python 2.7.13](https://www.python.org/downloads/release/python-2713/)

[SAMtools v. 1.5](https://sourceforge.net/projects/samtools/files/samtools/1.5/)

[SEQTK 1.2-r102-dirty](https://github.com/lh3/seqtk)

[VSEARCH 2.4.2](https://github.com/torognes/vsearch)

[BWA 0.7.15](https://sourceforge.net/projects/bio-bwa/files/)

[PicardTools 2.9.0](https://github.com/broadinstitute/picard/releases)

[GATK v.3.8.0](https://software.broadinstitute.org/gatk/download/archive) - [HaplotypeCaller](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_haplotypecaller_HaplotypeCaller.php)

[ENTROPY & ESTPOST](https://github.com/sylviakinosian/Pteridium_GBS_Pipeline/tree/master/entropy)



